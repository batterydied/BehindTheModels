{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfaff732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocessing import Preprocessor\n",
    "from asserts import asserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e70ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/student_habits_performance.csv')\n",
    "X = df.iloc[:, 1:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790e1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b7b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocessor.preprocess(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ec0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, learning_rate = 0.01, max_epochs = 100, treshold = 1e-6, batch_size = None):\n",
    "        self.weights = None\n",
    "        self.bias = 0\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.treshold = treshold\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        asserts(X_train, y_train)\n",
    "        \n",
    "        n_samples, n_features = X_train.shape\n",
    "        self.weights = np.random.randn(n_features)\n",
    "\n",
    "        batch_size = self.batch_size if self.batch_size else n_samples\n",
    "        previous_loss = float('-inf')\n",
    "\n",
    "        for _ in range(self.max_epochs):\n",
    "            indices = np.arange(n_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X_train = X_train[indices]\n",
    "            y_train = y_train[indices]\n",
    "            total_loss = 0\n",
    "\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                samples = X_train[i: i + batch_size]\n",
    "                true_vals = y_train[i: i + batch_size]\n",
    "\n",
    "                dW, dB = self.gradient_descent(samples, true_vals)\n",
    "                \n",
    "                update_w = self.learning_rate * dW\n",
    "                update_b = self.learning_rate * dB\n",
    "\n",
    "                self.weights -= update_w\n",
    "                self.bias -= update_b\n",
    "\n",
    "                error = samples @ self.weights + self.bias - true_vals\n",
    "                total_loss += np.sum(error ** 2)\n",
    "            \n",
    "            epoch_loss = total_loss / n_samples\n",
    "            if abs(epoch_loss - previous_loss) < self.treshold:\n",
    "                break\n",
    "            previous_loss = epoch_loss\n",
    "            \n",
    "        return [self.weights, self.bias]\n",
    "    \n",
    "    def gradient_descent(self, samples, true_vals):\n",
    "        n_samples = samples.shape[0]\n",
    "        preds = samples @ self.weights + self.bias\n",
    "        error = preds - true_vals\n",
    "        #mse = np.mean(error ** 2)\n",
    "        #print(f'MSE: {mse}')\n",
    "\n",
    "        dW = (2/n_samples) * samples.T @ error\n",
    "        dB = (2/n_samples) * np.sum(error)\n",
    "\n",
    "        return [dW, dB]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return X_test @ self.weights + self.bias\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        rss = np.sum((y_test - self.predict(X_test)) ** 2)\n",
    "        tss = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "        return 1 - rss/tss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbb34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8749327136796486)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "regressor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383aed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brokestudent/Desktop/Projects/Behind the Models/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input = [\n",
    "    [23, 'Female', 0.0, 1.2, 1.1, 'No', 85.0, 8.0, 'Fair', 6, 'Master', 'Average', 8, 'Yes'],\n",
    "    [20, 'Female', 6.9, 2.8, 2.3, 'No', 97.3, 4.6, 'Good', 6, 'High School', 'Average', 8, 'No'],\n",
    "    [21, 'Male', 1.4, 3.1, 1.3, 'No', 94.8, 8.0, 'Poor', 1, 'High School', 'Poor', 1, 'No'],\n",
    "    [23, 'Female', 1.0, 3.9, 1.0, 'No', 71.0, 9.2, 'Poor', 4, 'Master', 'Good', 1, 'Yes'],\n",
    "    [19, 'Female', 5.0, 4.4, 0.5, 'No', 90.9, 4.9, 'Fair', 3, 'Master', 'Good', 1, 'No'],\n",
    "    [24, 'Male', 7.2, 1.3, 0.0, 'No', 82.9, 7.4, 'Fair', 1, 'Master', 'Average', 4, 'No'],\n",
    "    [21, 'Female', 5.6, 1.5, 1.4, 'Yes', 85.8, 6.5, 'Good', 2, 'Master', 'Poor', 4, 'No'],\n",
    "    [21, 'Female', 4.3, 1.0, 2.0, 'Yes', 77.7, 4.6, 'Fair', 0, 'Bachelor', 'Average', 8, 'No'],\n",
    "    [23, 'Female', 4.4, 2.2, 1.7, 'No', 100.0, 7.1, 'Good', 3, 'Bachelor', 'Good', 1, 'No'],\n",
    "    [18, 'Female', 4.8, 3.1, 1.3, 'No', 95.4, 7.5, 'Good', 5, 'Bachelor', 'Good', 10, 'Yes'],\n",
    "    [19, 'Female', 4.6, 3.7, 0.8, 'No', 77.6, 5.8, 'Fair', 1, None, 'Good', 3, 'No'],\n",
    "]\n",
    "input = preprocessor.transform_input(input)\n",
    "my_pred = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c0f792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8959948778509672"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "lr = sklearn.linear_model.LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "sklearn_pred = lr.predict(X_train)\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e938e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions within 10 distance: 744\n",
      "0.992\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for pred1, pred2 in zip(my_pred, sklearn_pred):\n",
    "    if abs(pred1 - pred2) <= 10:\n",
    "        count += 1\n",
    "print(f\"Number of predictions within 10 distance: {count}\")\n",
    "print(count/len(my_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
